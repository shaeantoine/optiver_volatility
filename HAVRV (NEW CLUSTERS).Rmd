---
title: "HAVRV Preleminary Testing on New Clusters"
output: html_document
date: "2024-04-28"
---

```{r}
library(dplyr)
library(rugarch)
```


# Create a list of all of the stock file names
```{r}
dir_stocks <- "C:/Users/Jacob/Desktop/data/Optiver/individual_book_train"
all_stocks <- list.files(dir_stocks)
```

# Select 5 stocks at random
# THIS SHOULD BE CHANGED TO ENSURE CLASS BALANCE BETWEEN 4 CLUSTERS
```{r}
set.seed(123)

four_stocks <- sample(all_stocks, 4)

stock_files_list <- list()
for (i in four_stocks) {
  stock_files_list[[i]] <- read.csv(file.path(dir_stocks, i))
}

```


# Produce Num Order, WAP and Bid Ask Spread
```{r}

for (i in 1 : length(stock_files_list)) {
  stock_files_list[[i]] <- stock_files_list[[i]] %>% 
    mutate(WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1)) %>%
    mutate(BidAskSpread = ask_price1 / bid_price1 - 1) %>%
    mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2) %>%
    mutate(imbalance = (bid_size1 - ask_size1) / (bid_size1 + ask_size1))
}

```


# Strip each stock file of the 500 unique time buckets - 2000 time minute buckets
```{r}

bucket_list <- list()
for (j in 1 : length(stock_files_list)) {
  time_IDs <- unique(stock_files_list[[j]][, 1])[1:500]
  for (i in 1 : length(time_IDs)) {
    bucket <- stock_files_list[[j]] %>% filter(time_id == time_IDs[i])
    bucket_list[[length(bucket_list) + 1]] <- bucket
  }
}

bucket_list[[2000]]

```

# classify each of these buckets into one of the 4 clusters
# this produces a nested list of time buckets for each cluster
```{r}
bucket_bas <- list()
for (i in 1 : length(bucket_list)) {
  bas <- bucket_list[[i]] %>% pull(BidAskSpread, imbalance)
  bucket_bas[[i]] <- mean(bas)
}

km.out <- kmeans(bucket_bas, centers = 4, nstart = 20)


cluster_data_lists <- list()
clusters <- list()
for (i in 1:length(bucket_list)) {
  cluster <- km.out$cluster[[i]]

  if (!(cluster %in% clusters)) {
    cluster_data_lists[[cluster]] <- list()
  }
  clusters <- c(clusters, cluster)
  
  cluster_data_lists[[cluster]][[length(cluster_data_lists[[cluster]]) + 1]] <- bucket_list[[i]]
}

cluster_data_lists[[3]][[10]]
cluster_data_lists[[2]][[10]]

```


# Deriving the log returns for each time bucket
```{r}
cluster_log_r1 <- list()
for (j in 1 : 4) {
  log_r1 <- list()
  for (i in 1 : length(cluster_data_lists[[j]])) {
    sec <- cluster_data_lists[[j]][[i]] %>% pull(seconds_in_bucket)
    price <- cluster_data_lists[[j]][[i]] %>% pull(WAP)
    log_r <- log(price[-1] / price[1:(length(price) - 1)])
    log_r1[[i]] <- data.frame(time = sec[-1], log_return = log_r)
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[i]]$time)]
    if (length(time.no.change) > 0) {
      new.df <- data.frame(time = time.no.change, log_return = 0)
      log_r1[[i]] <- rbind(log_r1[[i]], new.df)
      log_r1[[i]] <- log_r1[[i]][order(log_r1[[i]]$time), ]
    }
  } 
  cluster_log_r1[[j]] <- log_r1
}

cluster_log_r1[[3]][[10]]
cluster_log_r1[[2]][[10]]

```


# Deriving the volatility for each time
```{r}
comp_vol <- function(x) {
  return(sqrt(sum(x ^ 2)))
}

cluster_vol <- list()
for (j in 1:4) {
  vol <- list()
  for (i in 1 : length(cluster_log_r1[[j]])) {
  cluster_log_r1[[j]][[i]] <- cluster_log_r1[[j]][[i]] %>% mutate(time_bucket = ceiling(time / 30)) # I DON'T KNOW ABOUT THIS
  vol[[i]] <- aggregate(log_return ~ time_bucket, data = cluster_log_r1[[j]][[i]], FUN = comp_vol)
  colnames(vol[[i]]) <- c('time_bucket', 'volatility')
  }
  cluster_vol[[j]] <- vol
}

cluster_vol[[3]][[10]]
cluster_vol[[2]][[10]]


```


# HAV-RV
```{r}
cluster_vol.train <- list()
cluster_vol.val <- list()

for (j in 1:4) { 
  vol.train <- list()
  vol.val <- list()
  
  for (i in 1:length(cluster_log_r1[[j]])) {
    vol.train[[i]] <- cluster_vol[[j]][[i]][1:16, ]  # First 16 Time buckets for Training
    vol.val[[i]] <- cluster_vol[[j]][[i]][-(1:11), ]  # Remaining 4 Time buckets for validation
  }
  
  cluster_vol.train[[j]] <- vol.train
  cluster_vol.val[[j]] <- vol.val
}
cluster_vol.train[[3]][[10]]
cluster_vol.train[[2]][[10]]

```

```{r}
# len.train <- length(vol.train[[1]]$volatility)
# list.HAV <- list()
# 
# for (i in 1 : length(vol)) {
#   mean.vol <- rep(0, len.train - 5)
#   for (j in 1 : 5) {
#     mean.vol <- mean.vol + vol.train[[i]]$volatility[j : (j + len.train - 6)] / 5
#   }
#   list.HAV[[i]] <- data.frame(vol = vol.train[[i]]$volatility[-(1:5)], 
#                               vol_1 = vol.train[[i]]$volatility[5:(len.train - 1)],
#                               mean_vol_5 = mean.vol)
# }

list_HAV_cluster <- list()

for (j in 1:4) {
  list_HAV <- list()
  for (i in 1:length(cluster_vol[[j]])) {
    len.train <- length(cluster_vol.train[[j]][[i]]$volatility)
    mean.vol <- rep(0, len.train - 5)
    
    for (k in 1:5) {
      mean.vol <- mean.vol + cluster_vol.train[[j]][[i]]$volatility[k:(k + len.train - 6)] / 5
    }
    
    list_HAV[[i]] <- data.frame(
      vol = cluster_vol.train[[j]][[i]]$volatility[-(1:5)], 
      vol_1 = cluster_vol.train[[j]][[i]]$volatility[5:(len.train - 1)],
      mean_vol_5 = mean.vol
    )
  }
  list_HAV_cluster[[j]] <- list_HAV
}

list_HAV_cluster[[3]][[10]] #checks
list_HAV_cluster[[2]][[10]]
list_HAV_cluster[[1]][[10]]

```

```{r}
# quar <- list()
# comp_quar <- function(x) {
#   return(length(x) / 3 * sum(x ^ 4))
# }
# for (i in 1 : length(log_r1)) {
#   quar[[i]] <- aggregate(log_return ~ time_bucket, data = log_r1[[i]], FUN = comp_quar)
#   colnames(quar[[i]]) <- c('time_bucket', 'quarticity')
# }
# 


cluster_quar <- list() 
comp_quar <- function(x) {
  return(length(x) / 3 * sum(x ^ 4))
}

for (j in 1:4) {  
  quar <- list()
  for (i in 1:length(cluster_log_r1[[j]])) {
    quar[[i]] <- aggregate(log_return ~ time_bucket, data = cluster_log_r1[[j]][[i]], FUN = comp_quar)
    colnames(quar[[i]]) <- c('time_bucket', 'quarticity')
  }
  cluster_quar[[j]] <- quar
}

cluster_quar[[3]][[10]]
cluster_quar[[2]][[10]]
```

```{r}

# # 
# HAV.wls.models <- list()
# 
# HAV.wls.models <- list()
# 
# for (i in 1 : length(vol)) {
#   # weight.HAV <- 0
  # HAV.wls.models[[i]] <- lm(vol ~ vol_1 + mean_vol_5, list.HAV[[i]],
  #                           weights = list.HAV[[i]]$vol_1 /
  #                             sqrt(quar[[i]]$quarticity[5:(len.train - 1)]))
# }

list_HAV_wls_cluster <- list()

for (j in 1:4) {
  HAV_wls_models <- list()
  for (i in 1:length(cluster_vol[[j]])) {
    len.train <- length(cluster_vol.train[[j]][[i]]$volatility)
    weights <- list_HAV_cluster[[j]][[i]]$vol_1 /
               sqrt(cluster_quar[[j]][[i]]$quarticity[5:(len.train - 1)])

    HAV_wls_models[[i]] <- lm(vol ~ vol_1 + mean_vol_5, data = list_HAV_cluster[[j]][[i]],
                              weights = weights)
  }
  list_HAV_wls_cluster[[j]] <- HAV_wls_models
}

list_HAV_wls_cluster[[3]][[1]]
list_HAV_wls_cluster[[2]][[1]]
```

```{r}

# 
# pred.lm <- list()
# 
# len.val <- length(vol.val[[1]]$volatility)
# list.HAV1 <- list()
# for (i in 1 : length(vol)) {
#   mean.vol <- rep(0, len.val - 5)
#   for (j in 1 : 5) {
#     mean.vol <- mean.vol + vol.val[[i]]$volatility[j : (j + len.val - 6)] / 5
#   }
#   list.HAV1[[i]] <- data.frame(vol = vol.val[[i]]$volatility[-(1:5)], 
#                               vol_1 = vol.val[[i]]$volatility[5:(len.val - 1)],
#                               mean_vol_5 = mean.vol)
#   pred.lm[[i]] <- predict(HAV.wls.models[[i]], newdata = list.HAV1[[i]])
# }cluster_pred_lm <- list()

cluster_pred_lm <- list()

for (j in 1:4) {
  pred.lm <- list()
  len.val <- length(cluster_vol.val[[j]][[1]]$volatility)  # Assumes that each cluster has at least one item
  list_HAV1_cluster <- list()

  for (i in 1:length(cluster_vol.val[[j]])) {
    mean.vol <- rep(0, len.val - 5)
    for (k in 1:5) {
      if ((k + len.val - 6) <= length(cluster_vol.val[[j]][[i]]$volatility)) {
        mean.vol <- mean.vol + cluster_vol.val[[j]][[i]]$volatility[k:(k + len.val - 6)] / 5
      }
    }
    list_HAV1_cluster[[i]] <- data.frame(
      vol = cluster_vol.val[[j]][[i]]$volatility[-(1:5)], 
      vol_1 = cluster_vol.val[[j]][[i]]$volatility[5:(len.val - 1)],
      mean_vol_5 = mean.vol
    )

    # Predict using the respective HAV model for this cluster
    pred.lm[[i]] <- predict(list_HAV_wls_cluster[[j]][[i]], newdata = list_HAV1_cluster[[i]])
  }
  
  cluster_pred_lm[[j]] <- pred.lm
}

```

```{r}
cluster_MSE_lm <- list()
cluster_QLIKE_lm <- list()
for (j in 1:4) {
  MSE.lm_1 <- vector()
  QLIKE.lm <- vector()
  for (i in 1:length(cluster_vol.val[[j]])) {
    tail_volatility = tail(cluster_vol.val[[j]][[i]]$volatility, 4)
    tail_prediction = tail(cluster_pred_lm[[j]][[i]], 4)
    MSE.lm_1 <- c(MSE.lm_1, mean((tail_volatility - tail_prediction)^2))
    QLIKE.lm <- c(QLIKE.lm, mean(tail_volatility / tail_prediction - 
                                 log(tail_volatility / tail_prediction) - 1))
  }
  cluster_MSE_lm[[j]] <- MSE.lm_1
  cluster_QLIKE_lm[[j]] <- QLIKE.lm
}

par(mfrow = c(2, 4))
for (j in 1:4) {
  boxplot(cluster_MSE_lm[[j]], horizontal = TRUE, main = paste("MSE Plot for cluster", j), ylim = c(0, 0.00001))
}
for (j in 1:4) {
  boxplot(cluster_QLIKE_lm[[j]], horizontal = TRUE, main = paste("QLIKE Plot for cluster", j), ylim = c(0, 2))
}


```







