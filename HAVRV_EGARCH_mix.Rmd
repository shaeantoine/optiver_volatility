---
title: "SVR_EGARCH_mix"
output: html_document
date: "2024-04-28"
---

```{r}
library(dplyr)
library(rugarch)
```


# Create a list of all of the stock file names
```{r}
dir_stocks <- "~/Documents/DATA3888/optiver_volatility/data/individual_book_train/"
all_stocks <- list.files(dir_stocks)
```

# Select 5 stocks at random
# THIS SHOULD BE CHANGED TO ENSURE CLASS BALANCE BETWEEN 4 CLUSTERS
```{r}
set.seed(123)

four_stocks <- sample(all_stocks, 4)

stock_files_list <- list()
for (i in four_stocks) {
  stock_files_list[[i]] <- read.csv(file.path(dir_stocks, i))
}

```


# Produce Num Order, WAP and Bid Ask Spread
```{r}

for (i in 1 : length(stock_files_list)) {
  stock_files_list[[i]] <- stock_files_list[[i]] %>% 
    mutate(WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1)) %>%
    mutate(BidAskSpread = ask_price1 / bid_price1 - 1) %>%
    mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2) %>%
    mutate(imbalance = (bid_size1 - ask_size1) / (bid_size1 + ask_size1))
}

```


# Strip each stock file of the 500 unique time buckets - 2000 time minute buckets
```{r}

bucket_list <- list()
for (j in 1 : length(stock_files_list)) {
  time_IDs <- unique(stock_files_list[[j]][, 1])[1:500]
  for (i in 1 : length(time_IDs)) {
    bucket <- stock_files_list[[j]] %>% filter(time_id == time_IDs[i])
    bucket_list[[length(bucket_list) + 1]] <- bucket
  }
}

bucket_list[[2000]]

```

# classify each of these buckets into one of the 4 clusters
# this produces a nested list of time buckets for each cluster
```{r}

bucket_bas <- list()
for (i in 1 : length(bucket_list)) {
  bas <- bucket_list[[i]] %>% pull(BidAskSpread, imbalance)
  bucket_bas[[i]] <- mean(bas)
}

km.out <- kmeans(bucket_bas, centers = 4, nstart = 20)


cluster_data_lists <- list()
clusters <- list()
for (i in 1:length(bucket_list)) {
  cluster <- km.out$cluster[[i]]

  if (!(cluster %in% clusters)) {
    cluster_data_lists[[cluster]] <- list()
  }
  clusters <- c(clusters, cluster)
  
  cluster_data_lists[[cluster]][[length(cluster_data_lists[[cluster]]) + 1]] <- bucket_list[[i]]
}

cluster_data_lists[[3]][[10]]

```


# Deriving the log returns for each time bucket
```{r}

# Single stock approach 

# log_r1 <- list()
# for (i in 1 : length(bucket_list)) {
#   sec <- bucket_list[[i]] %>% pull(seconds_in_bucket)
#   price <- bucket_list[[i]] %>% pull(WAP)
#   log_r <- log(price[-1] / price[1:(length(price) - 1)])
#   log_r1[[i]] <- data.frame(time = sec[-1], log_return = log_r)
#   time.no.change <- (1:600)[!(1:600 %in% log_r1[[i]]$time)]
#   if (length(time.no.change) > 0) {
#     new.df <- data.frame(time = time.no.change, log_return = 0)
#     log_r1[[i]] <- rbind(log_r1[[i]], new.df)
#     log_r1[[i]] <- log_r1[[i]][order(log_r1[[i]]$time), ]
#   }
# }
# 
# log_r1[[300]]

# Multiple time bucket approch - on cluster 3

# log_r1 <- list()
# for (i in 1 : length(cluster_data_lists[[3]])) {
#   sec <- cluster_data_lists[[1]][[i]] %>% pull(seconds_in_bucket)
#   price <- cluster_data_lists[[1]][[i]] %>% pull(WAP)
#   log_r <- log(price[-1] / price[1:(length(price) - 1)])
#   log_r1[[i]] <- data.frame(time = sec[-1], log_return = log_r)
#   time.no.change <- (1:600)[!(1:600 %in% log_r1[[i]]$time)]
#   if (length(time.no.change) > 0) {
#     new.df <- data.frame(time = time.no.change, log_return = 0)
#     log_r1[[i]] <- rbind(log_r1[[i]], new.df)
#     log_r1[[i]] <- log_r1[[i]][order(log_r1[[i]]$time), ]
#   }
# }
# 
# log_r1[[22]]

# Multiple time bucket approch - on all clusters

cluster_log_r1 <- list()
for (j in 1 : 4) {
  log_r1 <- list()
  for (i in 1 : length(cluster_data_lists[[j]])) {
    sec <- cluster_data_lists[[1]][[i]] %>% pull(seconds_in_bucket)
    price <- cluster_data_lists[[1]][[i]] %>% pull(WAP)
    log_r <- log(price[-1] / price[1:(length(price) - 1)])
    log_r1[[i]] <- data.frame(time = sec[-1], log_return = log_r)
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[i]]$time)]
    if (length(time.no.change) > 0) {
      new.df <- data.frame(time = time.no.change, log_return = 0)
      log_r1[[i]] <- rbind(log_r1[[i]], new.df)
      log_r1[[i]] <- log_r1[[i]][order(log_r1[[i]]$time), ]
    }
  } 
  cluster_log_r1[[j]] <- log_r1
}

cluster_log_r1[[4]][[1]]

```


# Deriving the volatility for each time
```{r}

# Single cluster approach 

# vol <- list()
# 
# comp_vol <- function(x) {
#   return(sqrt(sum(x ^ 2)))
# }
# 
# for (i in 1 : length(log_r1)) {
#   log_r1[[i]] <- log_r1[[i]] %>% mutate(time_bucket = ceiling(time / 30)) # I DON'T KNOW ABOUT THIS
#   vol[[i]] <- aggregate(log_return ~ time_bucket, data = log_r1[[i]], FUN = comp_vol)
#   colnames(vol[[i]]) <- c('time_bucket', 'volatility')
# }


# Multiple cluster approach 

comp_vol <- function(x) {
  return(sqrt(sum(x ^ 2)))
}

cluster_vol <- list()
for (j in 1:4) {
  vol <- list()
  for (i in 1 : length(cluster_log_r1[[j]])) {
  cluster_log_r1[[j]][[i]] <- cluster_log_r1[[j]][[i]] %>% mutate(time_bucket = ceiling(time / 30)) # I DON'T KNOW ABOUT THIS
  vol[[i]] <- aggregate(log_return ~ time_bucket, data = cluster_log_r1[[j]][[i]], FUN = comp_vol)
  colnames(vol[[i]]) <- c('time_bucket', 'volatility')
  }
  cluster_vol[[j]] <- vol
}

```


# EGARCH Development
```{r}
spec <- ugarchspec(variance.model = list(model = "eGARCH", garchOrder = c(1, 1)), 
                   mean.model = list(armaOrder = c(1, 1)), 
                   distribution.model = "norm")

cluster_GARCH_models <- list()
for (j in 1:4) {
  ARMA_GARCH.models <- list()
  for (i in 1 : length(cluster_vol[[j]])) {
    if (i%%10 == 0) {
      print(i)
    }
    ARMA_GARCH.models[[i]] <- ugarchfit(spec = spec, 
                                        data = cluster_log_r1[[j]][[i]] %>% 
                                               filter(time <= 480) %>%
                                               pull(log_return),
                                        solver = 'hybrid')
  } 
  cluster_GARCH_models[[j]] <- ARMA_GARCH.models
}

length(as.list(coef(cluster_GARCH_models[[1]][[103]])))

```

```{r}

# Single cluster
#
# RV.pred <- rep(0, length(vol))
# 
# for (i in 1 : length(vol)) {
#   fspec <- getspec(ARMA_GARCH.models[[i]])
#   setfixed(fspec) <- as.list(coef(ARMA_GARCH.models[[i]]))
#   future.path <- fitted(ugarchpath(fspec, n.sim = 30, m.sim = 1000))
#   # Due to numerical issues, sometimes NA value can be produced 
#   # We simply replace NA value with 0; you may come up with a better idea in your own project
#   future.path[is.na(future.path)] <- 0 
#   RV.pred[i] <- mean(sqrt(colSums(future.path ^ 2)))
# }
# 
# plot(RV.pred)


# Application on multiple clusters
# HAS NAs CAUSING PROBLEMS 
cluster_rv_pred <- list()
for (j in 1:4) {
  RV.pred <- rep(0, length(cluster_vol[[j]]))

  for (i in 1 : length(cluster_vol[[j]])) {
    fspec <- getspec(cluster_GARCH_models[[j]][[i]])
    if (length(as.list(coef(cluster_GARCH_models[[j]][[i]]))) == 0) {
      next
    }
    setfixed(fspec) <- as.list(coef(cluster_GARCH_models[[j]][[i]]))
    future.path <- fitted(ugarchpath(fspec, n.sim = 30, m.sim = 1000))
    # Due to numerical issues, sometimes NA value can be produced 
    # We simply replace NA value with 0; you may come up with a better idea in your own project
    future.path[is.na(future.path)] <- 0 
    RV.pred[i] <- mean(sqrt(colSums(future.path ^ 2)))
  }
  cluster_rv_pred[[j]] <- RV.pred
  
}

```

# Evaluation
```{r}

# Single cluster application
# vol.train <- list()
#
# vol.val <- list()
# 
# for (i in 1 : length(log_r1)) {
#   vol.train[[i]] <- vol[[i]][1:16, ]
#   vol.val[[i]] <- vol[[i]][-(1:16), ]
# }

# Multiple cluster application

cluster_vol_train <- list()
cluster_vol_val <- list()
for (j in 1:4) {
  vol.train <- list()
  vol.val <- list()
  
  for (i in 1 : length(cluster_log_r1[[j]])) {
    vol.train[[i]] <- cluster_vol[[j]][[i]][1:16, ]
    vol.val[[i]] <- cluster_vol[[j]][[i]][-(1:16), ]
  }
  cluster_vol_train[[j]] <- vol.train
  cluster_vol_val[[j]] <- vol.val
}


# Single cluster application 
cluster_vol_mean_test <- list()
cluster_vol_mean_train <- list()
for (j in 1:4) {
  vol_mean_test <- vector()
  vol_mean_train <- vector()
  for (i in 1 : length(cluster_vol[[j]])){
    vol_mean_test <- c(vol_mean_test, mean(cluster_vol_val[[j]][[i]]$volatility))
    vol_mean_train <- c(vol_mean_train, mean(cluster_vol_train[[j]][[i]]$volatility))
  }
  
  cluster_vol_mean_test[[j]] <- vol_mean_test
  cluster_vol_mean_train[[j]] <- vol_mean_train
}

```


# MSE and QLIKE
```{r}

for (j in 1:4) {
  MSE.lm <- vector()
  QLIKE.lm <- vector()
  for (i in 1 : length(cluster_vol[[j]])) {
    MSE.lm <- c(MSE.lm, mean((cluster_vol_val[[j]][[i]]$volatility - cluster_rv_pred[[j]][[i]]) ^ 2))
    QLIKE.lm <- c(QLIKE.lm, mean(cluster_vol_val[[j]][[i]]$volatility / cluster_rv_pred[[j]][[i]] - 
                                   log(cluster_vol_val[[j]][[i]]$volatility / cluster_rv_pred[[j]][[i]]) - 1))
  }
  
  max_index <- which.max(MSE.lm)
  
  MSE.lm_filtered <- MSE.lm[-max_index]
  
  boxplot(MSE.lm_filtered, horizontal = TRUE, main = "MSE")
  boxplot(QLIKE.lm, horizontal = TRUE, main = "QLIKE", ylim=c(0,2))
}


```

```{r}
# Set up the layout with 1 row and 2 columns for the figures
par(mfrow = c(2, 2))

# Initialize lists to store MSE and QLIKE values for each iteration
all_MSE <- list()
all_QLIKE <- list()

# Iterate over each iteration of the loop
for (j in 1:4) {
  MSE.lm <- vector()
  QLIKE.lm <- vector()
  
  # Calculate MSE and QLIKE values for each cluster in the current iteration
  for (i in 1:length(cluster_vol[[j]])) {
    MSE.lm <- c(MSE.lm, mean((cluster_vol_val[[j]][[i]]$volatility - cluster_rv_pred[[j]][[i]]) ^ 2))
    QLIKE.lm <- c(QLIKE.lm, mean(cluster_vol_val[[j]][[i]]$volatility / cluster_rv_pred[[j]][[i]] - 
                                   log(cluster_vol_val[[j]][[i]]$volatility / cluster_rv_pred[[j]][[i]]) - 1))
  }
  
  # Exclude the maximum MSE value for each iteration
  max_index <- which.max(MSE.lm)
  MSE.lm_filtered <- MSE.lm[-max_index]
  
  # Store MSE and QLIKE values for this iteration
  all_MSE[[j]] <- MSE.lm_filtered
  all_QLIKE[[j]] <- QLIKE.lm
  
  # Plot MSE values
  # boxplot(MSE.lm_filtered, horizontal = TRUE, main = "MSE")
}

for (j in 1:4) {
  boxplot(all_MSE[[j]], horizontal = TRUE, main = paste("MSE Plot for cluster", j), ylim = c(0, 0.000001))
}

# Plot QLIKE values
for (j in 1:4) {
  boxplot(all_QLIKE[[j]], horizontal = TRUE, main = paste("QLIKE Plot for cluster", j), ylim = c(0, 2))
}

# Reset the plotting settings to default
par(mfrow = c(1, 1))
```












